
@INPROCEEDINGS{1,
  author={Caramancion, Kevin Matthe},
  booktitle={2020 IEEE International IOT, Electronics and Mechatronics Conference (IEMTRONICS)}, 
  title={Understanding the Impact of Contextual Clues in Misinformation Detection}, 
  year={2020},
 keywords = {type:Misinformation-detection,Contextual,
papersource:IEEE,
datasetsource:USnews,
datatype:FakeNews,
component:content, component:context,
datamining:none,
evaluation:quantitative},
  volume={},
  number={},
  pages={1-6},
   url ={https://ieeexplore.ieee.org/document/9216394},
  doi={10.1109/IEMTRONICS51293.2020.9216394}}

@inproceedings{2,
author = {Khattar, Dhruv and Goud, Jaipal Singh and Gupta, Manish and Varma, Vasudeva},
title = {MVAE: Multimodal Variational Autoencoder for Fake News Detection},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313552},
doi = {10.1145/3308558.3313552},
abstract = {In recent times, fake news and misinformation have had a disruptive and adverse impact on our lives. Given the prominence of microblogging networks as a source of news for most individuals, fake news now spreads at a faster pace and has a more profound impact than ever before. This makes detection of fake news an extremely important challenge. Fake news articles, just like genuine news articles, leverage multimedia content to manipulate user opinions but spread misinformation. A shortcoming of the current approaches for the detection of fake news is their inability to learn a shared representation of multimodal (textual + visual) information. We propose an end-to-end network, Multimodal Variational Autoencoder (MVAE), which uses a bimodal variational autoencoder coupled with a binary classifier for the task of fake news detection. The model consists of three main components, an encoder, a decoder and a fake news detector module. The variational autoencoder is capable of learning probabilistic latent variable models by optimizing a bound on the marginal likelihood of the observed data. The fake news detector then utilizes the multimodal representations obtained from the bimodal variational autoencoder to classify posts as fake or not. We conduct extensive experiments on two standard fake news datasets collected from popular microblogging websites: Weibo and Twitter. The experimental results show that across the two datasets, on average our model outperforms state-of-the-art methods by margins as large as ~ 6% in accuracy and ~ 5% in F1 scores.},
booktitle = {The World Wide Web Conference},
pages = {2915–2921},
numpages = {7},
keywords = {type: Fake-news-detection,microblogs, multimodal fusion, variational autoencoders,
papersource:GoogleScholar,
datasetsource:Twitter,datasetsource:weibo,
datatype:FakeNews,datatype:Rumor,
component:content,picture,
datamining:unsupervised,
evaluation:quantitative},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@article{3,
title = {Misinformation detection using multitask learning with mutual learning for novelty detection and emotion recognition},
journal = {Information Processing & Management},
volume = {58},
number = {5},
pages = {102631},
year = {2021},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2021.102631},
url = {https://www.sciencedirect.com/science/article/pii/S0306457321001254},
author = {Rina Kumari and Nischal Ashok and Tirthankar Ghosal and Asif Ekbal},
keywords = {type:Fake news detection, Novelty prediction, Emotion recognition, Multitasking, Deep learning,
papersource:GoogleScholar,
datasetsource:Twitter,datasetsource:Zhihu,datasetsource:Reddit,datasetsource:bytedance,datasetsource:FNID,
datatype:FakeNews,
component:content,emotion,
datamining:machine-learning,datamining:deep-learning,
evaluation:quantitative},
abstract = {Fake news or misinformation is the information or stories intentionally created to deceive or mislead the readers. Nowadays, social media platforms have become the ripe grounds for misinformation, spreading them in a few minutes, which led to chaos, panic, and potential health hazards among people. The rapid dissemination and a prolific rise in the spread of fake news and misinformation create the most time-critical challenges for the Natural Language Processing (NLP) community. Relevant literature reveals that the presence of an element of surprise in the story is a strong driving force for the rapid dissemination of misinformation, which attracts immediate attention and invokes strong emotional stimulus in the reader. False stories or fake information are written to arouse interest and activate the emotions of people to spread it. Thus, false stories have a higher level of novelty and emotional content than true stories. Hence, Novelty of the news item and recognizing the Emotional state of the reader after reading the item seems two key tasks to tightly couple with misinformation Detection. Previous literature did not explore misinformation detection with mutual learning for novelty detection and emotion recognition to the best of our knowledge. Our current work argues that joint learning of novelty and emotion from the target text makes a strong case for misinformation detection. In this paper, we propose a deep multitask learning framework that jointly performs novelty detection, emotion recognition, and misinformation detection. Our deep multitask model achieves state-of-the-art (SOTA) performance for fake news detection on four benchmark datasets, viz. ByteDance, FNC, Covid-Stance and FNID with 7.73%, 3.69%, 7.95% and 13.38% accuracy gain, respectively. The evaluation shows that our multitask learning framework improves the performance over the single-task framework for four datasets with 7.8%, 28.62%, 11.46%, and 15.66% overall accuracy gain. We claim that textual novelty and emotion are the two key aspects to consider while developing an automatic fake news detection mechanism. The source code is available at https://github.com/Nish-19/Misinformation-Multitask-Attention-NE.}
}

@article{4,
title = {Dual emotion based fake news detection: A deep attention-weight update approach},
journal = {Information Processing & Management},
volume = {60},
number = {4},
pages = {103354},
year = {2023},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2023.103354},
url = {https://www.sciencedirect.com/science/article/pii/S0306457323000912},
author = {Alex Munyole Luvembe and Weimin Li and Shaohua Li and Fangfang Liu and Guiqiong Xu},
keywords = {type:Social media analysis, Emotions, Fake news detection, Adaptive genetic weight, Feature engineering,
papersource:GoogleScholar,
datasetsource:Twitter,datasetsource:Reddit,
datatype:FakeNews,datatype:Rumor,datatype:FakeReview,
component:content,emotion,component:context,
datamining:deep-learning,
evaluation:quantitative,evaluation:case-study},
abstract = {The proliferation of false information is a growing problem in today's dynamic online environment. This phenomenon requires automated detection of fake news to reduce its harmful effect on society. Even though various methods are used to detect fake news, most methods only consider data-oriented text features; ignoring dual emotion features (publisher emotions and social emotions) and thus lack higher levels of accuracy. This study addresses this issue by utilizing dual emotion features to detect fake news. The study proposes a Deep Normalized Attention-based mechanism for enriched extraction of dual emotion features and an Adaptive Genetic Weight Update-Random Forest (AGWu-RF) for classification. First, the deep normalized attention-based mechanism incorporates BiGRU, which improves feature value by extracting long-range context information to eliminate gradient explosion issues. The genetic weight for the model is adjusted to RF and updated to achieve optimized hyper parameter values ​​that support the classifiers' detection accuracy. The proposed model outperforms baseline methods on standard benchmark metrics in three real-world datasets. It outperforms state-of-the-art approaches by 5%, 11%, and 14% in terms of accuracy, highlighting the significance of dual emotion capabilities and optimizations in improving fake news detection.}
}

@inproceedings{5,
author = {Shu, Kai and Zhou, Xinyi and Wang, Suhang and Zafarani, Reza and Liu, Huan},
title = {The Role of User Profiles for Fake News Detection},
year = {2020},
isbn = {9781450368681},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341161.3342927},
doi = {10.1145/3341161.3342927},
abstract = {Consuming news from social media is becoming increasingly popular. Social media appeals to users due to its fast dissemination of information, low cost, and easy access. However, social media also enables the widespread of fake news. Due to the detrimental societal effects of fake news, detecting fake news has attracted increasing attention. However, the detection performance only using news contents is generally not satisfactory as fake news is written to mimic true news. Thus, there is a need for an in-depth understanding on the relationship between user profiles on social media and fake news. In this paper, we study the problem of understanding and exploiting user profiles on social media for fake news detection. In an attempt to understand connections between user profiles and fake news, first, we measure users' sharing behaviors and group representative users who are more likely to share fake and real news; then, we perform a comparative analysis of explicit and implicit profile features between these user groups, which reveals their potential to help differentiate fake news from real news. To exploit user profile features, we demonstrate the usefulness of these user profile features in a fake news classification task. We further validate the effectiveness of these features through feature importance analysis. The findings of this work lay the foundation for deeper exploration of user profile features of social media and enhance the capabilities for fake news detection.},
booktitle = {Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {436–439},
numpages = {4},
location = {Vancouver, British Columbia, Canada},
keywords = {type:Fake news detection, User,
papersource:SpringerOpen,
datasetsource:FakeNewsNet,datasetsource:Twitter,
datatype:FakeNews,
component:creator,
datamining:deep-learning,datamining:unsupervised,
evaluation:quantitative},
series = {ASONAM '19}
}


@inproceedings{6,
    title = "Cross-document Misinformation Detection based on Event Graph Reasoning",
    author = "Wu, Xueqing  and
      Huang, Kung-Hsiang  and
      Fung, Yi  and
      Ji, Heng",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.40",
    doi = "10.18653/v1/2022.naacl-main.40",
    pages = "543--558",
keywords = {type:Fake news detection, Contexual,
papersource:GoogleScholar,
datasetsource:self,
datatype:FakeNews,
component:content,component:context,
datamining:deep-learning,
evaluation:quantitative,evaluation:volunteer},
    abstract = "For emerging events, human readers are often exposed to both real news and fake news. Multiple news articles may contain complementary or contradictory information that readers can leverage to help detect fake news. Inspired by this process, we propose a novel task of cross-document misinformation detection. Given a cluster of topically related news documents, we aim to detect misinformation at both document level and a more fine-grained level, event level. Due to the lack of data, we generate fake news by manipulating real news, and construct 3 new datasets with 422, 276, and 1,413 clusters of topically related documents, respectively. We further propose a graph-based detector that constructs a cross-document knowledge graph using cross-document event coreference resolution and employs a heterogeneous graph neural network to conduct detection at two levels. We then feed the event-level detection results into the document-level detector. Experimental results show that our proposed method significantly outperforms existing methods by up to 7 F1 points on this new task.",
}

Scopus
EXPORT DATE: 08 May 2023

@ARTICLE{7,
	author = {Zou, Haochen and Wang, Zitao},
	title = {A semi-supervised short text sentiment classification method based on improved Bert model from unlabelled data},
	year = {2023},
	journal = {Journal of Big Data},
	volume = {10},
	number = {1},
	doi = {10.1186/s40537-023-00710-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150724375&doi=10.1186%2fs40537-023-00710-x&partnerID=40&md5=c462fd15df84aee9c0c0287e4e2dec31},
	affiliations = {School of Computer Science and Engineering, Nanjing University of Science and Technology, 200 Xiaolingwei Street Xuanwu District, Nanjing, 210094, China; Department of Computer Science and Software Engineering, Concordia University,  2155 Guy Street, Montreal, H3H 2L9, Canada},
	keywords = {type:Data enhancement; Data imbalance; Language models, Semi-supervised learning,Sentiment analysis,
papersource:Scopus,
datasetsource:Amazon,
datatype:FakeReview,
component:content,component:emotion,
datamining:deep-learning,datamining:semi-supervised,
evaluation:quantitative},
	correspondence_address = {H. Zou; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, 200 Xiaolingwei Street Xuanwu District, 210094, China; email: zouhaochen1996@126.com},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {21961115},
	language = {English},
	abbrev_source_title = {J. Big Data},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@inproceedings{8,
    title = "Rumor Detection by Exploiting User Credibility Information, Attention and Multi-task Learning",
    author = "Li, Quanzhi  and
      Zhang, Qiong  and
      Si, Luo",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1113",
    doi = "10.18653/v1/P19-1113",
    pages = "1173--1179",
keywords = {type:Rumor detection, User,
papersource:GoogleScholar,
datasetsource:Twitter,
datatype:FakeNews,
component:creator,
datamining:deep-learning,
evaluation:quantitative},
    abstract = "In this study, we propose a new multi-task learning approach for rumor detection and stance classification tasks. This neural network model has a shared layer and two task specific layers. We incorporate the user credibility information into the rumor detection layer, and we also apply attention mechanism in the rumor detection process. The attended information include not only the hidden states in the rumor detection layer, but also the hidden states from the stance detection layer. The experiments on two datasets show that our proposed model outperforms the state-of-the-art rumor detection approaches.",
}

@inproceedings{9,
author = {Yang, Shuo and Shu, Kai and Wang, Suhang and Gu, Renjie and Wu, Fan and Liu, Huan},
title = {Unsupervised Fake News Detection on Social Media: A Generative Approach},
year = {2019},
isbn = {978-1-57735-809-1},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v33i01.33015644},
doi = {10.1609/aaai.v33i01.33015644},
abstract = {Social media has become one of the main channels for people to access and consume news, due to the rapidness and low cost of news dissemination on it. However, such properties of social media also make it a hotbed of fake news dissemination, bringing negative impacts on both individuals and society. Therefore, detecting fake news has become a crucial problem attracting tremendous research effort. Most existing methods of fake news detection are supervised, which require an extensive amount of time and labor to build a reliably annotated dataset. In search of an alternative, in this paper, we investigate if we could detect fake news in an unsupervised manner. We treat truths of news and users' credibility as latent random variables, and exploit users' engagements on social media to identify their opinions towards the authenticity of news. We leverage a Bayesian network model to capture the conditional dependencies among the truths of news, the users' opinions, and the users' credibility. To solve the inference problem, we propose an efficient collapsed Gibbs sampling approach to infer the truths of news and the users' credibility without any labelled data. Experiment results on two datasets show that the proposed method significantly outperforms the compared unsupervised methods.},
booktitle = {Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {692},
numpages = {8},
keywords = {type:Fake news detection;Contexual;User,
papersource:GoogleScholar,
datasetsource:Twitter,datasetsource:Facebook,datasetsource:Buzzfeed,
datatype:FakeNews,
component:creator,
datamining:machine-learning,datamining:unsupervised,
evaluation:quantitative},
location = {Honolulu, Hawaii, USA},
series = {AAAI'19/IAAI'19/EAAI'19}
}

@inproceedings{10,
author = {Shu, Kai and Wang, Suhang and Liu, Huan},
title = {Beyond News Contents: The Role of Social Context for Fake News Detection},
year = {2019},
isbn = {9781450359405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3289600.3290994},
doi = {10.1145/3289600.3290994},
abstract = {Social media is becoming popular for news consumption due to its fast dissemination, easy access, and low cost. However, it also enables the wide propagation of fake news, i.e., news with intentionally false information. Detecting fake news is an important task, which not only ensures users receive authentic information but also helps maintain a trustworthy news ecosystem. The majority of existing detection algorithms focus on finding clues from news contents, which are generally not effective because fake news is often intentionally written to mislead users by mimicking true news. Therefore, we need to explore auxiliary information to improve detection. The social context during news dissemination process on social media forms the inherent tri-relationship, the relationship among publishers, news pieces, and users, which has the potential to improve fake news detection. For example, partisan-biased publishers are more likely to publish fake news, and low-credible users are more likely to share fake news. In this paper, we study the novel problem of exploiting social context for fake news detection. We propose a tri-relationship embedding framework TriFN, which models publisher-news relations and user-news interactions simultaneously for fake news classification. We conduct experiments on two real-world datasets, which demonstrate that the proposed approach significantly outperforms other baseline methods for fake news detection.},
booktitle = {Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining},
pages = {312–320},
numpages = {9},
keywords = {type:joint learning;social media mining;fake news detection,
papersource:ACM,
datasetsource:Twitter,datasetsource:Buzzfeed,datasetsource:FakeNewsNet,
datatype:FakeNews,
component:background,
datamining:semi-supervised,
evaluation:quantitative},
location = {Melbourne VIC, Australia},
series = {WSDM '19}
}